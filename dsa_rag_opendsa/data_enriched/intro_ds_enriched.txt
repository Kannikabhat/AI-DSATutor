Chunk_0e_1:
Computer science is the study of information—how it is organized, processed, and used. While "information" itself is an abstract concept and cannot be precisely defined (like a "point" in geometry), it can be measured and manipulated. The basic unit of information is the bit, representing one of two mutually exclusive states (e.g., ON or OFF).

Chunk_0e_2:
When a device can be in more than two states, more bits are required. For example, a dial with 8 positions can be represented using 3 bits, since 2³ = 8. A combination of three switches (bits) provides 8 possible configurations (000 to 111), allowing binary representation of each position.

Chunk_0e_3:
Bits are grouped into strings to represent data. A string like 101011 represents six switches (bits) with specified ON/OFF states. Binary numbers interpret these positions as powers of 2. For example, 00100110 = 2¹ + 2² + 2⁵ = 38. With n bits, we can represent integers from 0 to 2ⁿ − 1.

Chunk_0e_4:
Negative integers are represented using complement systems. In one's complement, we flip each bit of the positive binary number (e.g., ~00100110 = 11011001 for -38). In two's complement, we add 1 to the one's complement, resulting in 11011010. Two’s complement avoids ambiguity by having only one representation for 0.

Chunk_0e_5:
Binary Coded Decimal (BCD) uses 4 bits to represent each decimal digit (0 to 9). For example, 0010 represents 2 and 0110 represents 6, so 00100110 becomes 26. However, not all 4-bit combinations are valid in BCD—only the first ten are used.

Chunk_0e_6:
Floating-point representation stores real numbers as mantissa × base^exponent. In a typical format, 32 bits are divided into a 24-bit two's complement mantissa and an 8-bit exponent. For example, 387.53 becomes mantissa = 38753, exponent = -2, and base = 10. This allows representation of very large or very small values.

Chunk_0e_7:
The main benefit of floating-point notation is range. Numbers like 10^127 or 10^-178 can be stored. However, only 23 bits of precision are available in the mantissa, meaning that very precise numbers must be approximated, limiting accuracy.

Chunk_0e_8:
Non-numeric data such as names and addresses are stored as character strings. Each character is assigned a bit string (e.g., 11000000 = 'A', 11000001 = 'B'). Strings like "AB" are stored as concatenated character bit patterns. The character encoding system (e.g., ASCII, Unicode) must be used consistently for interpretation.

Chunk_0e_9:
Different machines use varying byte sizes for characters — some use 7 bits (128 characters), some 8 (256 characters), and some 10 (1024). A byte is defined as the number of bits used to represent a character. Not all possible bit combinations are used in practice; many remain unused.

Chunk_0e_10:
Bit patterns by themselves have no meaning. Their interpretation defines their purpose — the same bit pattern can represent an integer, character, or real number depending on the data type. Data types act as interpretive rules, giving semantics to raw binary.

Chunk_0e_11:
Computer memory is a collection of addressable bits, often grouped into bytes or words. Each unit (byte or word) is given a unique numeric address (e.g., byte 746). The content at that address is a bit pattern, and it's the programmer’s job to interpret that pattern correctly.

Chunk_0e_12:
Computers have native data types hardwired into their architecture. For example, adding two integers involves extracting operand bits, performing binary addition, and storing the result. Instructions like these implicitly treat bit patterns as integers or real numbers based on the operation type.

Chunk_0e_13:
High-level languages like C help by introducing declarations. When a programmer writes int x, y; float a, b;, the compiler knows that x and y are integers, and a and b are floating-point numbers. The compiler then selects the appropriate instructions for operations like a = a + b.

Chunk_0e_14:
Declarations define how memory should be interpreted, how much memory to allocate, and how operations should behave. Operators like + are generic — their meaning depends on operand types. The compiler uses declarations to resolve ambiguity and apply the right logic.

Chunk_0e_15:
Abstract Data Types (ADTs) allow us to focus on logical structure rather than implementation. Instead of worrying about hardware instructions, we define what operations a type must support (e.g., add, delete, update) and implement those using existing types. Implementation may be done in hardware or software.

Chunk_0e_16:
For example, suppose a computer supports a MOVE(source, dest, length) instruction to copy a fixed-length string. But we want to implement a variable-length string MOVEVAR(source, dest) instead. We can do this by prepending a length byte before the string, so the software reads the length before copying.

Chunk_0e_17:
To support MOVEVAR, we define the data type as a length-prefixed character string: the first byte holds the length (≤ 255), followed by that many characters. This representation allows the program to interpret the first byte as the size and copy accordingly — a software-based implementation of a new data type using old ones.

Chunk_0e_18:
By abstracting data types, we can define stacks, queues, trees, and more, regardless of machine hardware. These are implemented in software through data structures — organized, logical groupings of memory and rules. Data structures are the practical toolset for implementing ADTs.
